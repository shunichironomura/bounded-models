# Testing Sampler Coverage of Valid Space

When users define custom validators and samplers, ensuring the sampler covers the entire valid space is a fundamental challenge. This document outlines practical strategies for detecting coverage gaps.

## The Challenge

```python
class Model(BoundedModel):
    code: str

    @validator("code")
    def validate_code(cls, v):
        # Complex validation logic
        return (len(v) == 6 and
                v[:2].isalpha() and
                v[2:].isdigit() and
                int(v[2:]) % 7 == 0)

    @sampler("code")
    def sample_code(self):
        # Does this actually generate ALL valid codes?
        letters = self._random_string(2, charset="alpha_upper")
        # Bug: only generates multiples of 14, not all multiples of 7
        number = self._random.choice([0, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 91, 98]) * 7
        return f"{letters}{number:04d}"
```

## Strategy 1: Coverage Tracking with Buckets

Divide the value space into buckets and track which ones get sampled:

```python
from collections import defaultdict
from bounded_models import CoverageTracker

class CoverageTest:
    def test_code_coverage(self):
        tracker = CoverageTracker(Model, "code")

        # Define buckets for analysis
        tracker.add_bucket("letter_pairs", lambda v: v[:2])
        tracker.add_bucket("number_range", lambda v: int(v[2:]) // 100)
        tracker.add_bucket("mod_7_class", lambda v: int(v[2:]) % 7)

        # Sample many times
        for _ in range(10000):
            model = Model.sample()
            tracker.observe(model.code)

        # Analyze coverage
        report = tracker.get_report()
        assert report.get_bucket_coverage("letter_pairs") > 0.95  # 95% of letter pairs
        assert report.get_bucket_coverage("mod_7_class") == 1.0   # All mod 7 classes

        # Find missing patterns
        missing = tracker.find_missing_patterns()
        print(f"Never saw these patterns: {missing}")
```

## Strategy 2: Adversarial Value Search

Actively search for valid values the sampler doesn't generate:

```python
from bounded_models import AdversarialTester

class AdversarialTest:
    def test_find_gaps(self):
        tester = AdversarialTester(Model, "code")

        # Try to find valid values not generated by sampler
        gaps = tester.find_coverage_gaps(
            num_samples=10000,
            search_strategies=[
                "boundary_mutation",    # Mutate near boundaries
                "pattern_extension",    # Extend seen patterns
                "systematic_search",    # Systematic enumeration
                "gradient_search"       # For numeric spaces
            ]
        )

        if gaps:
            print(f"Found {len(gaps)} valid values never sampled:")
            for value in gaps[:10]:
                assert Model.validate_code(value)  # Confirm it's valid
                print(f"  {value}")
```

## Strategy 3: Statistical Coverage Estimation

Use statistical methods to estimate coverage without exhaustive testing:

```python
from bounded_models import CoverageEstimator

class StatisticalTest:
    def test_coverage_estimation(self):
        estimator = CoverageEstimator(Model, "code")

        # Sample and build coverage model
        samples = [Model.sample().code for _ in range(1000)]

        # Estimate total valid space size
        space_size = estimator.estimate_valid_space_size(samples)
        unique_seen = len(set(samples))

        # Statistical coverage estimate
        coverage = estimator.estimate_coverage(
            samples_seen=unique_seen,
            total_samples=1000,
            estimated_space_size=space_size
        )

        print(f"Estimated coverage: {coverage:.2%}")
        print(f"Confidence interval: {estimator.confidence_interval()}")

        # Prediction: how many samples needed for 99% coverage?
        samples_needed = estimator.samples_for_coverage(0.99)
        print(f"Need ~{samples_needed} samples for 99% coverage")
```

## Strategy 4: Dual Specification Testing

Require explicit value space definition and test both validator and sampler against it:

```python
from bounded_models import ValueSpace, BoundedModel

class ExplicitModel(BoundedModel):
    code: str

    # Explicit value space definition
    @value_space("code")
    def code_space(self) -> ValueSpace:
        return CompositeSpace(
            CrossProduct(
                CharacterSet("ABCDEFGHIJKLMNOPQRSTUVWXYZ", length=2),
                IntegerSet(0, 9999, filter=lambda n: n % 7 == 0)
            ),
            formatter=lambda parts: f"{parts[0]}{parts[1]:04d}"
        )

    # Validator must accept exactly the value space
    @validator("code")
    def validate_code(cls, v):
        return cls.code_space().contains(v)

    # Sampler must sample from the value space
    @sampler("code")
    def sample_code(self):
        return self.code_space().sample()
```

## Strategy 5: Distribution Analysis

Analyze the sampling distribution to detect systematic gaps:

```python
from bounded_models import DistributionAnalyzer
import matplotlib.pyplot as plt

class DistributionTest:
    def test_distribution_uniformity(self):
        analyzer = DistributionAnalyzer(Model, "code")

        # Collect samples
        samples = [Model.sample().code for _ in range(10000)]

        # Analyze distribution
        analysis = analyzer.analyze(samples)

        # Check for uniformity
        assert analysis.uniformity_score() > 0.95

        # Detect gaps in continuous spaces
        gaps = analysis.find_gaps(min_gap_size=0.01)
        assert len(gaps) == 0, f"Found gaps in distribution: {gaps}"

        # Visualize distribution
        analysis.plot_distribution("code_distribution.png")

        # Check specific properties
        letter_dist = analysis.marginal_distribution(lambda v: v[:2])
        assert letter_dist.is_uniform(tolerance=0.1)
```

## Strategy 6: Metamorphic Testing

Test relationships between valid values:

```python
from bounded_models import MetamorphicTester

class MetamorphicTest:
    def test_metamorphic_relations(self):
        tester = MetamorphicTester(Model, "code")

        # Define metamorphic relations
        @tester.relation("increment_valid")
        def increment_relation(code: str) -> str:
            """If code is valid, incrementing by 7 should also be valid"""
            letters = code[:2]
            number = int(code[2:]) + 7
            if number <= 9999:
                return f"{letters}{number:04d}"
            return None

        # Test that sampler respects relations
        violations = tester.test_relations(num_samples=1000)
        assert len(violations) == 0

        # Use relations to explore coverage
        explored = tester.explore_via_relations(
            initial_samples=100,
            max_iterations=10
        )
        print(f"Discovered {len(explored)} values via metamorphic exploration")
```

## Strategy 7: Time-Based Coverage Analysis

Track how coverage improves over time to detect convergence:

```python
from bounded_models import CoverageMonitor

class TimeBasedTest:
    def test_coverage_convergence(self):
        monitor = CoverageMonitor(Model, "code")

        # Monitor coverage over time
        for i in range(10000):
            model = Model.sample()
            monitor.observe(model.code)

            if i % 1000 == 0:
                coverage = monitor.estimate_coverage()
                new_discoveries = monitor.new_discoveries_rate()
                print(f"After {i} samples: {coverage:.2%} coverage, "
                      f"{new_discoveries:.4f} discovery rate")

        # Check if we've converged
        assert monitor.has_converged(threshold=0.001)

        # Estimate remaining undiscovered values
        remaining = monitor.estimate_remaining()
        print(f"Estimated {remaining} values not yet discovered")
```

## Strategy 8: Property-Based Coverage Testing

Define properties that characterize complete coverage:

```python
from bounded_models import property_test

class PropertyTest:
    @property_test
    def test_all_prefixes_covered(self):
        """Every valid 2-letter prefix should appear in samples"""
        samples = [Model.sample().code for _ in range(10000)]
        prefixes = set(s[:2] for s in samples)

        # Check all letter combinations
        for l1 in "ABCDEFGHIJKLMNOPQRSTUVWXYZ":
            for l2 in "ABCDEFGHIJKLMNOPQRSTUVWXYZ":
                prefix = l1 + l2
                # Try to construct a valid code with this prefix
                valid_code = f"{prefix}0007"  # 7 is valid
                if Model.validate_code(valid_code):
                    assert prefix in prefixes, f"Never sampled prefix: {prefix}"

    @property_test
    def test_modulo_classes_covered(self):
        """All modulo 7 classes should be represented"""
        samples = [Model.sample().code for _ in range(10000)]
        mod_classes = set(int(s[2:]) % 7 for s in samples)

        # Should only have 0 (since validator requires % 7 == 0)
        assert mod_classes == {0}
```

## Strategy 9: Fuzzing-Based Validation

Use fuzzing to find edge cases:

```python
from bounded_models import CoverageFuzzer

class FuzzingTest:
    def test_fuzzing_coverage(self):
        fuzzer = CoverageFuzzer(Model, "code")

        # Start with sampled values and mutate
        coverage_gaps = fuzzer.fuzz(
            initial_samples=100,
            mutations=[
                fuzzer.swap_characters,
                fuzzer.increment_numbers,
                fuzzer.boundary_values,
                fuzzer.pattern_mixing
            ],
            max_iterations=10000
        )

        print(f"Fuzzing found {len(coverage_gaps)} new valid values")

        # These should all be valid but potentially not sampled
        for value in coverage_gaps:
            assert Model.validate_code(value)
```

## Best Practices

### 1. Explicit Value Space When Possible
```python
# Better: Explicit enumeration for small spaces
VALID_CODES = [f"{l1}{l2}{n:04d}"
               for l1 in "ABC" for l2 in "XYZ"
               for n in range(0, 1000, 7)]

@sampler("code")
def sample_code(self):
    return self._random.choice(VALID_CODES)
```

### 2. Document Sampling Strategy
```python
@sampler("code")
def sample_code(self):
    """
    Samples uniformly from:
    - All 26x26 letter pairs
    - All 4-digit multiples of 7 (0000-9996)

    Coverage: Complete
    """
    letters = self._random_string(2, charset="alpha_upper")
    number = self._random.randint(0, 1428) * 7  # 0 to 9996
    return f"{letters}{number:04d}"
```

### 3. Test Coverage in CI/CD
```python
# Run coverage tests in continuous integration
class CoverageCI:
    def test_sampler_coverage(self):
        report = run_coverage_analysis(
            Model,
            fields=["code"],
            samples=10000,
            strategies=["buckets", "adversarial", "statistical"]
        )

        assert report.estimated_coverage() > 0.99
        assert report.high_confidence()

        # Save report for tracking
        report.save("coverage_report.json")
```

### 4. Incremental Coverage Improvement
```python
# Use coverage feedback to improve sampler
@sampler("code")
def sample_code(self):
    if self._random.random() < 0.1:
        # 10% chance to try to fill coverage gaps
        return self._sample_from_gaps()
    else:
        # 90% normal sampling
        return self._normal_sample()
```

## Conclusion

Perfect coverage verification is often impossible, but these strategies help:

1. **Statistical confidence** rather than absolute proof
2. **Multiple complementary approaches** to find different types of gaps
3. **Continuous monitoring** to track coverage over time
4. **Explicit specifications** when the space is enumerable
5. **Property-based testing** to verify coverage characteristics

The key is to make coverage gaps visible and provide tools to detect and fix them incrementally.
